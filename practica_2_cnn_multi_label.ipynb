{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes: ['tempImages/002_24fab375.jpg', 'tempImages/010_18d7b27c.jpg', 'tempImages/010_2f9c83bc.jpg']\n",
      "Etiquetas: [[1, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Rutas para guardar las imágenes y etiquetas\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Cargar y procesar el archivo CSV\n",
    "with open(\"../test/tempImagesLabels.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Saltar la cabecera\n",
    "\n",
    "    for row in reader:\n",
    "        # Obtener ruta de la imagen y convertir las etiquetas de string a lista de enteros\n",
    "        image_paths.append(row[0])\n",
    "        labels.append(list(map(int, row[1].strip(\"[]\").split(\", \"))))\n",
    "\n",
    "# Verificar resultados\n",
    "print(\"Imágenes:\", image_paths[:3])  # Muestra los primeros 3 elementos\n",
    "print(\"Etiquetas:\", labels[:3])      # Muestra los primeros 3 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datos de imágenes: (10, 128, 128, 3)\n",
      "Forma de las etiquetas: (10, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dimensiones a las que redimensionar las imágenes\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "image_data = []\n",
    "for image_path in image_paths:\n",
    "    # Cargar imagen desde archivo\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    # Convertir la imagen a un array numpy\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    # Normalizar los valores de los píxeles (0-255 a 0-1)\n",
    "    img_array = img_array / 255.0\n",
    "    image_data.append(img_array)\n",
    "\n",
    "# Convertir a tensores para entrenar\n",
    "image_data = np.array(image_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Verificar formas\n",
    "print(\"Forma de los datos de imágenes:\", image_data.shape)\n",
    "print(\"Forma de las etiquetas:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: (7, 128, 128, 3)\n",
      "Datos de validación: (1, 128, 128, 3)\n",
      "Datos de prueba: (2, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en entrenamiento (70%), validación (15%) y prueba (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(image_data, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Datos de validación: {X_val.shape}\")\n",
    "print(f\"Datos de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el generador de datos para entrenamiento con data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalizar las imágenes\n",
    "    rotation_range=40,  # Rotar las imágenes aleatoriamente\n",
    "    width_shift_range=0.2,  # Desplazamiento horizontal\n",
    "    height_shift_range=0.2,  # Desplazamiento vertical\n",
    "    shear_range=0.2,  # Cizallamiento\n",
    "    zoom_range=0.2,  # Zoom aleatorio\n",
    "    horizontal_flip=True,  # Voltear imágenes horizontalmente\n",
    "    fill_mode='nearest'  # Método de relleno para píxeles faltantes\n",
    ")\n",
    "\n",
    "# Generador de datos para la validación (sin data augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Ajustar las imágenes a los generadores\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train_generator: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples in train_generator:\", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de modelo con parámetros de búsqueda\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Primera capa Conv2D con parámetros de búsqueda para el número de filtros y tamaño del kernel\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size_1', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Segunda capa Conv2D con parámetros de búsqueda\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters_2', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size_2', values=[3, 5]),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Aplanar la salida\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Capa densa con número de unidades a ser optimizado\n",
    "    model.add(Dense(\n",
    "        hp.Int('units', min_value=64, max_value=256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "\n",
    "    # Capa de salida con activación sigmoid para clasificación binaria\n",
    "    model.add(Dense(labels.shape[1], activation='sigmoid'))\n",
    "\n",
    "    # Compilar el modelo con tasa de aprendizaje como un parámetro de búsqueda\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el objeto de búsqueda de hiperparámetros\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,  # Función que construye el modelo\n",
    "    objective='val_accuracy',  # Objetivo de optimización\n",
    "    max_epochs=10,  # Número máximo de épocas\n",
    "    hyperband_iterations=2,  # Número de iteraciones de Hyperband\n",
    "    directory='cnn_models',  # Directorio donde se guardarán los resultados\n",
    "    project_name='cnn_multi_label'  # Nombre del proyecto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 Complete [00h 00m 13s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 04m 47s\n"
     ]
    }
   ],
   "source": [
    "# Realizar la búsqueda de hiperparámetros\n",
    "tuner.search(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "F1 Score (ponderado): 0.6666666666666666\n",
      "\n",
      "Reporte de clasificación:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.12      1.00      0.22         1\n",
      "   macro avg       0.08      0.17      0.11         1\n",
      "weighted avg       0.50      1.00      0.67         1\n",
      " samples avg       0.12      0.50      0.20         1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonibix23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "c:\\Users\\gonibix23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\gonibix23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\gonibix23\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_binary = (y_pred > THRESHOLD).astype(int)  # Convertir probabilidades a etiquetas binarias\n",
    "\n",
    "# Calcular F1 Score\n",
    "f1 = f1_score(y_test, y_pred_binary, average='weighted')  # Para clasificación multi-clase\n",
    "print(f\"F1 Score (ponderado): {f1}\")\n",
    "\n",
    "# Reporte de clasificación detallado\n",
    "print(\"\\nReporte de clasificación:\\n\")\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Pérdida (Loss)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "# Pérdida (Loss)\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history['loss'], 'r', label='Training Loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Precisión (Accuracy)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history['accuracy'], 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
